{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8f08ed-0ecb-4a11-979d-1af17a268665",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 1: SCHEMA EVOLUTION Demo\n",
    "\n",
    "Simulate adding new column `payment_method` to source data.\n",
    "Iceberg handles schema changes automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9846aa8-f351-4305-9837-112b9970b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'payment_method' added!\n",
      "+---------------+---------+-------+\n",
      "|col_name       |data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|event_time     |timestamp|NULL   |\n",
      "|event_type     |string   |NULL   |\n",
      "|product_id     |int      |NULL   |\n",
      "|category_id    |bigint   |NULL   |\n",
      "|category_code  |string   |NULL   |\n",
      "|brand          |string   |NULL   |\n",
      "|price          |double   |NULL   |\n",
      "|user_id        |int      |NULL   |\n",
      "|user_session   |string   |NULL   |\n",
      "|_ingestion_time|timestamp|NULL   |\n",
      "|_source_file   |string   |NULL   |\n",
      "|payment_method |string   |NULL   |\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new column to Bronze table (Schema Evolution)\n",
    "spark.sql(\"\"\"\n",
    "    ALTER TABLE lakehouse.bronze.ecommerce_events \n",
    "    ADD COLUMN payment_method STRING\n",
    "\"\"\")\n",
    "\n",
    "print(\"Column 'payment_method' added!\")\n",
    "spark.sql(\"DESCRIBE lakehouse.bronze.ecommerce_events\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d29617-6fb1-4c3f-b7e0-248f3c752ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+------+--------------+\n",
      "|event_time         |brand  |price |payment_method|\n",
      "+-------------------+-------+------+--------------+\n",
      "|2019-10-02 10:00:00|samsung|599.99|credit_card   |\n",
      "|2019-10-02 11:00:00|apple  |999.99|paypal        |\n",
      "+-------------------+-------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Insert new data with the new column (simulating Day T+1 data)\n",
    "from datetime import datetime\n",
    "\n",
    "new_data = [\n",
    "    (datetime(2019, 10, 2, 10, 0, 0), \"purchase\", 12345, 1234567890, \"electronics.phone\",\n",
    "     \"samsung\", 599.99, 100001, \"new-session-001\", datetime.now(), \"demo_day2.csv\", \"credit_card\"),\n",
    "\n",
    "    (datetime(2019, 10, 2, 11, 0, 0), \"purchase\", 12346, 1234567890, \"electronics.phone\",\n",
    "     \"apple\", 999.99, 100002, \"new-session-002\", datetime.now(), \"demo_day2.csv\", \"paypal\"),\n",
    "]\n",
    "\n",
    "\n",
    "schema = spark.table(\"lakehouse.bronze.ecommerce_events\").schema\n",
    "df_new = spark.createDataFrame(new_data, schema)\n",
    "\n",
    "df_new.writeTo(\"lakehouse.bronze.ecommerce_events\").append()\n",
    "\n",
    "# Verify - old data has NULL for payment_method, new data has values\n",
    "spark.sql(\"\"\"\n",
    "    SELECT event_time, brand, price, payment_method \n",
    "    FROM lakehouse.bronze.ecommerce_events \n",
    "    WHERE payment_method IS NOT NULL OR brand = 'samsung'\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c49f29f-5dda-4d8c-9a73-5e08b0b9ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('event_time', TimestampType(), True), StructField('event_type', StringType(), True), StructField('product_id', IntegerType(), True), StructField('category_id', LongType(), True), StructField('category_code', StringType(), True), StructField('brand', StringType(), True), StructField('price', DoubleType(), True), StructField('user_id', IntegerType(), True), StructField('user_session', StringType(), True), StructField('_ingestion_time', TimestampType(), True), StructField('_source_file', StringType(), True), StructField('payment_method', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db67d49-42f8-4fef-97be-815feab9d41f",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 2: TIME TRAVEL Demo\n",
    "\n",
    "Query historical snapshots of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9dbc615-6081-4e8b-85ce-4dc9568e87ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TABLE HISTORY ===\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2026-01-30 04:10:44.685|9127348836860691094|NULL               |true               |\n",
      "|2026-01-30 04:19:26.313|6471009077848248100|9127348836860691094|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View table history\n",
    "print(\"=== TABLE HISTORY ===\")\n",
    "spark.sql(\"SELECT * FROM lakehouse.bronze.ecommerce_events.history\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c8f388-4e3d-4108-a876-d7f30f2be9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SNAPSHOTS ===\n",
      "+-------------------+-----------------------+---------+\n",
      "|snapshot_id        |committed_at           |operation|\n",
      "+-------------------+-----------------------+---------+\n",
      "|8345581712853693656|2026-01-30 04:04:51.168|append   |\n",
      "|8961319236875262264|2026-01-30 04:08:08.245|append   |\n",
      "|7909682360207467037|2026-01-30 04:09:21.43 |append   |\n",
      "|4160572160808099697|2026-01-30 04:10:06.081|append   |\n",
      "|9127348836860691094|2026-01-30 04:10:44.685|append   |\n",
      "|6471009077848248100|2026-01-30 04:19:26.313|append   |\n",
      "+-------------------+-----------------------+---------+\n",
      "\n",
      "First snapshot ID: 8345581712853693656\n"
     ]
    }
   ],
   "source": [
    "# View snapshots\n",
    "print(\"=== SNAPSHOTS ===\")\n",
    "snapshots_df = spark.sql(\"SELECT snapshot_id, committed_at, operation FROM lakehouse.bronze.ecommerce_events.snapshots\")\n",
    "snapshots_df.show(truncate=False)\n",
    "\n",
    "# Get first snapshot ID for time travel\n",
    "first_snapshot = snapshots_df.orderBy(\"committed_at\").first()[\"snapshot_id\"]\n",
    "print(f\"First snapshot ID: {first_snapshot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40759732-dadd-46d3-a11e-2f9bb2f392f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA AT FIRST SNAPSHOT (before new column) ===\n",
      "+-----------------+\n",
      "|count_at_snapshot|\n",
      "+-----------------+\n",
      "|          3533286|\n",
      "+-----------------+\n",
      "\n",
      "=== CURRENT DATA (after inserts) ===\n",
      "+-------------+\n",
      "|current_count|\n",
      "+-------------+\n",
      "|      4264754|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cột count_at_snapshot là gì\n",
    "\n",
    "# Query data at first snapshot (before schema evolution)\n",
    "print(\"=== DATA AT FIRST SNAPSHOT (before new column) ===\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT COUNT(*) as count_at_snapshot   \n",
    "    FROM lakehouse.bronze.ecommerce_events \n",
    "    VERSION AS OF {first_snapshot}\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"=== CURRENT DATA (after inserts) ===\")\n",
    "spark.sql(\"SELECT COUNT(*) as current_count FROM lakehouse.bronze.ecommerce_events\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
