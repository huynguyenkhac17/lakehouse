version: "3.8"

x-spark-common: &spark-common
  build: ./spark
  networks:
    - lakehouse-net
  volumes:
    - ./spark/conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf

services:
  # STORAGE
  minio:
    image: minio/minio:latest
    container_name: lakehouse-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
    command: server /data --console-address ":9001"
    volumes:
      - ./minio/data:/data
    networks:
      - lakehouse-net

  # METADATA DB
  postgres:
    image: postgres:13
    container_name: lakehouse-postgres
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"
    volumes:
      - ./init/postgres-init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - lakehouse-net

  # CATALOG
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: lakehouse-hms
    depends_on:
      - postgres
    # command: ["/bin/bash", "-c", "sleep 3600"]
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: "-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore_db -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=password"
    ports:
      - "9083:9083"
    networks:
      - lakehouse-net

  # COMPUTE
  spark-master:
    <<: *spark-common
    container_name: lakehouse-spark-master
    # Khởi động Master cho image Apache
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"
      - "7077:7077"
  
  spark-worker:
    <<: *spark-common
    container_name: lakehouse-spark-worker
    depends_on:
      - spark-master
    # Khởi động Worker cho image Apache
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G

  spark-thrift-server:
    <<: *spark-common
    container_name: lakehouse-thrift-server
    depends_on:
      - spark-master
      - hive-metastore
      - postgres
    environment:
      - SPARK_CONF_DIR=/opt/spark/conf
      - HADOOP_CONF_DIR=/opt/spark/conf
    command: /opt/spark/sbin/start-thriftserver.sh --master spark://spark-master:7077 --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.server2.thrift.bind.host=0.0.0.0 --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
    ports:
      - "10000:10000"
      - "4040:4040"

  # NOTEBOOK
  jupyter:
    build: ./spark
    container_name: lakehouse-jupyter
    user: root
    command: >
      bash -c "pip install jupyterlab pyspark==3.5.1 && 
               jupyter-lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=''"
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/spark/work
      - ./spark/conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - lakehouse-net

networks:
  lakehouse-net:
    driver: bridge